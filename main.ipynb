{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hand Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd  \n",
    "import os \n",
    "import pathlib\n",
    "import glob\n",
    "\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf  \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model  \n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import of the images \n",
    "and create dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4862 files belonging to 4 classes.\n",
      "Using 3404 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-13 15:42:57.915800: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 110592000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'getexif'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/wiz/git/HandRecognition/main.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mPIL\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mExifTags\u001b[39;00m \u001b[39mimport\u001b[39;00m TAGS\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m train_ds:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=22'>23</a>\u001b[0m     \u001b[39m# extracting the exif metadata\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=23'>24</a>\u001b[0m     exifdata \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mgetexif()\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=25'>26</a>\u001b[0m     \u001b[39m# looping through all the tags present in exifdata\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=26'>27</a>\u001b[0m     \u001b[39mfor\u001b[39;00m tagid \u001b[39min\u001b[39;00m exifdata:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=27'>28</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wiz/git/HandRecognition/main.ipynb#ch0000003vscode-remote?line=28'>29</a>\u001b[0m         \u001b[39m# getting the tag name instead of tag id\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'getexif'"
     ]
    }
   ],
   "source": [
    "#Image paramters\n",
    "batch_size = 10\n",
    "img_height = 720\n",
    "img_width = 1280\n",
    "\n",
    "#image directories\n",
    "image_dir = data_dir = pathlib.Path(\"dataset\")   #Setting image directory\n",
    "\n",
    "#creating dataset with validation split\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  image_dir,\n",
    "  validation_split=0.3,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "#plot some image examples\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize the data, since we want smaller values for the RGB channels. We do so by creating a Rescaling layer, which will then be added to the CNN just after the input layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
